# -*- coding: utf-8 -*-
"""Titanic_tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iZuLIYljNw8Z4v6Wvs8kydlpt0y3URw1
"""

import numpy as np
import pandas as pd
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Loading train, test and sample submission
train_data = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
submision = pd.read_csv('gender_submission.csv')

# Analyzing null values in training data
train_data.isnull().sum()

# Analyzing training data
train_data

# Here 'Survived' is output feature and for input we will consider 'Pclass', 'Sex', 'Age', 'Sib', 'Parch', 'Fare' and 'Embarked'
train_y = train_data['Survived']
train_x = train_data.drop(columns = ['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])

# Handling with missing data in Age( by taking median classwise) and Embarked( by taking most frequent class)

# For Embarked
train_x.Embarked.fillna('S', inplace = True )

# For Age
grouped_train = train_data.iloc[:891].groupby(['Sex','Pclass'])
grouped_median_train = grouped_train.median()
grouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Age']]

def fill_age(row):
    condition = (
        (grouped_median_train['Sex'] == row['Sex']) &  
        (grouped_median_train['Pclass'] == row['Pclass'])
    ) 
    return grouped_median_train[condition]['Age'].values[0]


def process_age():
    global train_x
    # a function that fills the missing values of the Age variable
    train_x['Age'] = train_x.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)
    return train_x

train_x = process_age()

train_x.isnull().sum() # No missing values

# Feature engineering which include encoding of Sex feature ( Male as 1 and female as 0)
train_x['Sex'].replace({'male':0, 'female':1}, inplace = True)

# Feature engineering which include creating dummy variables (separate features encoded as 0 and 1) for Embarked and Pclass
embarked_dummies = pd.get_dummies(train_x['Embarked'], prefix='Embarked')
train_x = pd.concat([train_x, embarked_dummies], axis=1)
train_x = train_x.drop(columns = 'Embarked')
class_dummies = pd.get_dummies(train_x['Pclass'], prefix='class')
train_x = pd.concat([train_x, class_dummies], axis=1)
train_x = train_x.drop(columns = 'Pclass')

# Feature engineering which include the merging of parch and SibSp to create FamilySize as Single, small and large
def process_family():
    
    global train_x
    # introducing a new feature : the size of families (including the passenger)
    train_x['FamilySize'] = train_data['Parch'] + train_data['SibSp'] + 1
    
    # introducing other features based on the family size
    train_x['Singleton'] = train_x['FamilySize'].map(lambda s: 1 if s == 1 else 0)
    train_x['SmallFamily'] = train_x['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)
    train_x['LargeFamily'] = train_x['FamilySize'].map(lambda s: 1 if 5 <= s else 0)
    
    
    return train_x
train_x = process_family()

# Dropping useless features and rounding the feature Fare into 2 decimal place
train_x = train_x.drop(columns = ['FamilySize', 'SibSp', 'Parch'])
train_x['Fare'] = train_x['Fare'].round(decimals = 2)

# So train_x and train_y
train_x

train_y

# Analyzing null values in test data
test.isnull().sum()

# Analyzing test data
test

# Here input feature are 'Pclass', 'Sex', 'Age', 'Sib', 'Parch', 'Fare' and 'Embarked'
test = test.drop(columns = ['PassengerId', 'Name', 'Ticket', 'Cabin'])

# Handling with missing data in Age( by taking median classwise) and Embarked( by taking most frequent class)

# For Age we will consider the same set of medians as we have considered in case of training data
def process_age2():
    global test
    # a function that fills the missing values of the Age variable
    test['Age'] = test.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)
    return test

test = process_age2()

test.isnull().sum() # No missing values

# Feature engineering which include encoding of Sex feature ( Male as 1 and female as 0)
test['Sex'].replace({'male':0, 'female':1}, inplace = True)

# Feature engineering which include creating dummy variables (separate features encoded as 0 and 1) for Embarked and Pclass
embarked_dummies2 = pd.get_dummies(test['Embarked'], prefix='Embarked')
test = pd.concat([test, embarked_dummies2], axis=1)
test = test.drop(columns = 'Embarked')
class_dummies2 = pd.get_dummies(test['Pclass'], prefix='class')
test = pd.concat([test, class_dummies2], axis=1)
test = test.drop(columns = 'Pclass')

# Feature engineering which include the merging of parch and SibSp to create FamilySize as Single, small and large
def process_family2():
    
    global test
    # introducing a new feature : the size of families (including the passenger)
    test['FamilySize'] = test['Parch'] + test['SibSp'] + 1
    
    # introducing other features based on the family size
    test['Singleton'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)
    test['SmallFamily'] = test['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)
    test['LargeFamily'] = test['FamilySize'].map(lambda s: 1 if 5 <= s else 0)
    
    
    return test
test = process_family2()

# Dropping useless features and rounding the feature Fare into 2 decimal place
test = test.drop(columns = ['FamilySize', 'SibSp', 'Parch'])
test['Fare'] = test['Fare'].round(decimals = 2)

# So test data
test

# Creating model
model = RandomForestClassifier()
model.fit(train_x, train_y)

# Checking accuracy
predict_train = model.predict(train_x)
accuracy = accuracy_score(train_y, predict_train)
accuracy   # 97.97% accuracy on training data

# Getting result for test data and storing in submission.csv ( 2 columns passengerId and survived)
test_predict = model.predict(test)
test_predict = pd.DataFrame(test_predict)
Submission = pd.concat([submision, test_predict], axis = 1)
Submission.rename(columns = {0 : 'Survived'}, inplace = True)

# Submission data
Submission

# Saving submission file
Submission.to_csv('Submission.csv', index = False)